{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN FIRST (Imports & Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import scanpy as sc\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import mmread\n",
    "import mygene\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(data, meta, color=None):\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced = pca.fit_transform(data)\n",
    "\n",
    "    #plt.figure(figsize=(7,6))\n",
    "    #sns.scatterplot(x=reduced[:, 0], y=reduced[:, 1])\n",
    "\n",
    "    if color:\n",
    "        for category in color:\n",
    "            plt.figure(figsize=(7,6))\n",
    "            sns.scatterplot(x=reduced[:, 0], y=reduced[:, 1], hue=meta[category])\n",
    "\n",
    "def plot_umap(data, meta, color=None, partial_fit=1.0, figsize=(7, 6)):\n",
    "    umap = UMAP(n_components=2)\n",
    "    #fit_data, fit_meta, left_data, left_meta = train_test_split()\n",
    "    reduced = umap.fit_transform(data)\n",
    "\n",
    "    #plt.figure(figsize=(7,6))\n",
    "    #sns.scatterplot(x=redu\n",
    "    # ced[:, 0], y=reduced[:, 1])\n",
    "\n",
    "    if color:\n",
    "        for category in color:\n",
    "            plt.figure(figsize=figsize)\n",
    "            sns.scatterplot(x=reduced[:, 0], y=reduced[:, 1], hue=meta[category])\n",
    "\n",
    "def prepare_raw_from_h5ad(data, debug=False):\n",
    "        matrix = pd.DataFrame(data.X.todense())\n",
    "        matrix.columns = data.var.index\n",
    "        matrix.index = data.obs.index\n",
    "        metadata = data.obs\n",
    "        if debug:\n",
    "            print(f'Prepared matrix with shape {matrix.shape}')\n",
    "        return (matrix, metadata)\n",
    "\n",
    "def process_h5ad(folder, tissue, threshold=0.2, only_filtered=False):\n",
    "\n",
    "    # Process h5 data\n",
    "    h5raw = sc.read_h5ad(f'{folder}/{tissue}.h5ad')\n",
    "    sc.pp.normalize_total(h5raw, target_sum=1e4)\n",
    "    sc.pp.log1p(h5raw, base=10)\n",
    "\n",
    "    # PCR by scanpy\n",
    "    #sc.tl.pca(h5raw)\n",
    "    #sc.pl.pca(h5raw, color=['method', 'age', 'sex'], title=f'PCA: lung', save='result.png')\n",
    "\n",
    "    def prepare_raw_from_h5ad(data, debug=False):\n",
    "        matrix = pd.DataFrame(data.X.todense())\n",
    "        matrix.columns = data.var.index\n",
    "        matrix.index = data.obs.index\n",
    "        metadata = data.obs\n",
    "        if debug:\n",
    "            print(f'Prepared matrix with shape {matrix.shape}')\n",
    "        return (matrix, metadata)\n",
    "\n",
    "    h5_data, metadata = prepare_raw_from_h5ad(h5raw)\n",
    "    #h5_input = h5_data.to_numpy()\n",
    "\n",
    "    if not only_filtered:\n",
    "        np.save(f'{folder}/{tissue}_full_genes.npy', list(h5_data.columns))\n",
    "        np.save(f'{folder}/{tissue}_full.npy', h5_data)\n",
    "\n",
    "    # Add age info into metadata\n",
    "    ages = [59, 61, 57, 38, 40, 67, 69, 56, 37, 33, 42, 74, 22, 59, 46]\n",
    "    donor2age = {f'TSP{i+1}':j for i, j in enumerate(ages)}\n",
    "    metadata['age'] = metadata.apply(lambda row: donor2age[row.donor], axis=1)\n",
    "\n",
    "    metadata.to_csv(f'{folder}/{tissue}_meta.csv')\n",
    "    \n",
    "\n",
    "    # Remove all genes which are expressed in less than X of cells\n",
    "    # Very robust and straightforward way to reduce # features\n",
    "    cell_threshold = int(h5_data.shape[0] * threshold)\n",
    "    filtered_data = (h5_data.loc[:,h5_data.astype(bool).sum(axis=0) > cell_threshold])\n",
    "    filt_input = filtered_data.to_numpy()\n",
    "\n",
    "    np.save(f'{folder}/{tissue}_filtered_genes.npy', list(filtered_data.columns))\n",
    "    np.save(f'{folder}/{tissue}_filtered.npy', filt_input)\n",
    "\n",
    "\n",
    "def combine_tissues_and_methods_both(tissues, output_name, threshold=0.2):\n",
    "    combined_data = None\n",
    "    combined_metadata = None\n",
    "\n",
    "    \n",
    "    for tissue in tissues:\n",
    "        droplet_data_present = False\n",
    "        facs_data_present = False\n",
    "        \n",
    "        try:\n",
    "            droplet_h5raw = sc.read_h5ad(f'data/mouse/droplet_{tissue}.h5ad')\n",
    "            d_h5_data, d_metadata = prepare_raw_from_h5ad(droplet_h5raw)\n",
    "            droplet_data_present = True\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Droplet data for {tissue} not found.\")\n",
    "        \n",
    "        try:\n",
    "            facs_h5raw = sc.read_h5ad(f'data/mouse/facs_{tissue}.h5ad')\n",
    "            f_h5_data, f_metadata = prepare_raw_from_h5ad(facs_h5raw)\n",
    "            facs_data_present = True\n",
    "        except FileNotFoundError:\n",
    "            print(f\"FACS data for {tissue} not found.\")\n",
    "        \n",
    "        if droplet_data_present and facs_data_present:\n",
    "            # Identify common columns\n",
    "            common_columns = d_h5_data.columns.intersection(f_h5_data.columns)\n",
    "            # Filter both DataFrames to only include common columns\n",
    "            d_filtered = d_h5_data[common_columns]\n",
    "            f_filtered = f_h5_data[common_columns]\n",
    "            # Concatenate by rows\n",
    "            X = pd.concat([d_filtered, f_filtered])\n",
    "            y = pd.concat([d_metadata, f_metadata])\n",
    "        elif droplet_data_present:\n",
    "            X = d_h5_data\n",
    "            y = d_metadata\n",
    "        elif facs_data_present:\n",
    "            X = f_h5_data\n",
    "            y = f_metadata\n",
    "        else:\n",
    "            print(f\"No data available for {tissue} using either method.\")\n",
    "            continue\n",
    "        \n",
    "        if combined_data is None:\n",
    "            combined_data = X\n",
    "            combined_metadata = y\n",
    "        else:\n",
    "            combined_data = pd.concat([combined_data, X])\n",
    "            combined_metadata = pd.concat([combined_metadata, y])\n",
    "    \n",
    "    if combined_data is not None:\n",
    "        # Filter out genes with too few cells\n",
    "        threshold_n_cells = int(combined_data.shape[0] * threshold)\n",
    "        filtered_data = combined_data.loc[:, combined_data.astype(bool).sum(axis=0) > threshold_n_cells]\n",
    "        combined_metadata['age'] = combined_metadata['age'].str.extract(r'(\\d+)').astype(int)\n",
    "        combined_metadata.rename(columns={'mouse.id': 'donor'}, inplace=True)\n",
    "\n",
    "        # Print the total number of rows and columns in the combined data\n",
    "        print(f\"Combined data dimensions: {filtered_data.shape[0]} rows, {filtered_data.shape[1]} columns\")\n",
    "\n",
    "        combined_metadata.to_csv(f'data/mouse/{output_name}_meta.csv')\n",
    "        np.save(f'data/mouse/{output_name}_filtered_genes.npy', list(filtered_data.columns))\n",
    "        np.save(f'data/mouse/{output_name}_filtered.npy', filtered_data.to_numpy())\n",
    "    else:\n",
    "        print(\"No combined data was created, please check the availability of the input files.\")\n",
    "\n",
    "\n",
    "def h5ad_to_pandas(folder, method, tissue):\n",
    "\n",
    "    # Process h5 data\n",
    "    h5raw = sc.read_h5ad(f'{folder}/{method}_{tissue}.h5ad')\n",
    "    sc.pp.normalize_total(h5raw, target_sum=1e4)\n",
    "    sc.pp.log1p(h5raw, base=10)\n",
    "\n",
    "    # PCR by scanpy\n",
    "    #sc.tl.pca(h5raw)\n",
    "    #sc.pl.pca(h5raw, color=['method', 'age', 'sex'], title=f'PCA: lung', save='result.png')\n",
    "\n",
    "    def prepare_raw_from_h5ad(data, debug=False):\n",
    "        matrix = pd.DataFrame(data.X.todense())\n",
    "        matrix.columns = data.var.index\n",
    "        matrix.index = data.obs.index\n",
    "        metadata = data.obs\n",
    "        if debug:\n",
    "            print(f'Prepared matrix with shape {matrix.shape}')\n",
    "        return (matrix, metadata)\n",
    "\n",
    "    h5_data, metadata = prepare_raw_from_h5ad(h5raw)\n",
    "    #h5_input = h5_data.to_numpy()\n",
    "\n",
    "    return metadata, h5_data\n",
    "\n",
    "def analysis(datasets):\n",
    "    for dataset in datasets:\n",
    "        print(dataset.shape)\n",
    "\n",
    "\n",
    "def load_h5ad_data(folder, tissue, filtered=True):\n",
    "    \n",
    "    H5_FOLDER = f'data/{folder}'\n",
    "    tissue = tissue\n",
    "\n",
    "    if filtered:\n",
    "        df_type = 'filtered'\n",
    "    else:\n",
    "        df_type = 'full'\n",
    "\n",
    "    gene_list = np.load(f'{H5_FOLDER}/{tissue}_{df_type}_genes.npy')\n",
    "    X = np.load(f'{H5_FOLDER}/{tissue}_{df_type}.npy')\n",
    "    metadata = pd.read_csv(f'{H5_FOLDER}/{tissue}_meta.csv', index_col=0)\n",
    "        \n",
    "    y = deepcopy(metadata)\n",
    "    print(f'Data shape: {X.shape}')\n",
    "\n",
    "    return (X, y, gene_list)\n",
    "\n",
    "\n",
    "def combine_methods_for_tissues(tissues, threshold=0.05):\n",
    "    for tissue in tissues:\n",
    "        droplet_h5raw = sc.read_h5ad(f'data/mouse/droplet_{tissue}.h5ad')\n",
    "        facs_h5raw = sc.read_h5ad(f'data/mouse/facs_{tissue}.h5ad')\n",
    "        d_h5_data, d_metadata = prepare_raw_from_h5ad(droplet_h5raw)\n",
    "        f_h5_data, f_metadata = prepare_raw_from_h5ad(facs_h5raw)\n",
    "\n",
    "        # Step 1: Identify common columns\n",
    "        common_columns = d_h5_data.columns.intersection(f_h5_data.columns)\n",
    "\n",
    "        # Step 2: Filter both DataFrames to only include common columns\n",
    "        d_filtered = d_h5_data[common_columns]\n",
    "        f_filtered = f_h5_data[common_columns]\n",
    "\n",
    "        # Step 3: Concatenate by rows\n",
    "        X = pd.concat([d_filtered, f_filtered])\n",
    "        y = pd.concat([d_metadata, f_metadata])\n",
    "\n",
    "        # Step 4: Filter out genes with too few cells\n",
    "        threshold_n_cells = int(X.shape[0] * threshold)\n",
    "        filtered_data = X.loc[:,X.astype(bool).sum(axis=0) > threshold_n_cells]\n",
    "        y['age'] = y['age'].str.extract(r'(\\d+)').astype(int)\n",
    "        y.rename(columns={'mouse.id': 'donor'}, inplace=True)\n",
    "\n",
    "        #plot_pca(filtered_data, y, color=('method',))\n",
    "\n",
    "        # Print the total number of rows and columns in the combined data\n",
    "        print(f\"Combined data dimensions: {filtered_data.shape[0]} rows, {filtered_data.shape[1]} columns\")\n",
    "        \n",
    "        y.to_csv(f'data/mouse/{tissue}_meta.csv')\n",
    "        np.save(f'data/mouse/{tissue}_filtered_genes.npy', list(filtered_data.columns))\n",
    "        if threshold == 0:\n",
    "            np.save(f'data/mouse/{tissue}.npy', filtered_data.to_numpy())\n",
    "        else:\n",
    "            np.save(f'data/mouse/{tissue}_filtered.npy', filtered_data.to_numpy())\n",
    "\n",
    "\n",
    "def combine_FACS_tissues(tissues, output_name, threshold=0.2):\n",
    "    combined_data = None\n",
    "    combined_metadata = None\n",
    "\n",
    "    for tissue in tissues:\n",
    "        facs_h5raw = sc.read_h5ad(f'data/mouse/facs_{tissue}.h5ad')\n",
    "        X, y = prepare_raw_from_h5ad(facs_h5raw)\n",
    "\n",
    "        if combined_data is None:\n",
    "            combined_data = X\n",
    "            combined_metadata = y\n",
    "        else:\n",
    "            combined_data = pd.concat([combined_data, X])\n",
    "            combined_metadata = pd.concat([combined_metadata, y])\n",
    "\n",
    "    # Step 4: Filter out genes with too few cells\n",
    "    threshold_n_cells = int(combined_data.shape[0] * threshold)\n",
    "    filtered_data = combined_data.loc[:, combined_data.astype(bool).sum(axis=0) > threshold_n_cells]\n",
    "    combined_metadata['age'] = combined_metadata['age'].str.extract(r'(\\d+)').astype(int)\n",
    "    combined_metadata.rename(columns={'mouse.id': 'donor'}, inplace=True)\n",
    "\n",
    "    # Print the total number of rows and columns in the combined data\n",
    "    print(f\"Combined data dimensions: {filtered_data.shape[0]} rows, {filtered_data.shape[1]} columns\")\n",
    "\n",
    "    combined_metadata.to_csv(f'data/mouse/{output_name}_meta.csv')\n",
    "    np.save(f'data/mouse/{output_name}_filtered_genes.npy', list(filtered_data.columns))\n",
    "    np.save(f'data/mouse/{output_name}_filtered.npy', filtered_data.to_numpy())\n",
    "\n",
    "\n",
    "def load_data(dataset, tissue, filtered=True, normalize=False, verbose=True):\n",
    "    H5_FOLDER = f'data/{dataset}'\n",
    "    tissue = tissue\n",
    "\n",
    "    if filtered:\n",
    "        df_type = 'filtered'\n",
    "    else:\n",
    "        df_type = 'full'\n",
    "\n",
    "    gene_list = np.load(f'{H5_FOLDER}/{tissue}_{df_type}_genes.npy')\n",
    "    X = np.load(f'{H5_FOLDER}/{tissue}_{df_type}.npy')\n",
    "    metadata = pd.read_csv(f'{H5_FOLDER}/{tissue}_meta.csv', index_col=0)\n",
    "        \n",
    "    y = deepcopy(metadata)\n",
    "    \n",
    "    if normalize:\n",
    "        X = np.log1p(X)\n",
    "        if verbose:\n",
    "            print('Data normalized.')\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Data shape: {X.shape}')\n",
    "    return (X, y, gene_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabula Muris Senis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once to rename\n",
    "\n",
    "import os\n",
    "\n",
    "for file_path in glob.glob(\"/Users/mindblaze/Desktop/Thesis/clocks/data/mouse/*droplet*\"):\n",
    "    os.rename(file_path, '/Users/mindblaze/Desktop/Thesis/clocks/data/mouse/droplet_'+file_path.split('-')[-1])\n",
    "    \n",
    "for file_path in glob.glob(\"/Users/mindblaze/Desktop/Thesis/clocks/data/mouse/*facs*\"):\n",
    "    os.rename(file_path, '/Users/mindblaze/Desktop/Thesis/clocks/data/mouse/facs_'+file_path.split('-')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tissues with one and both cell-ssorting methods\n",
    "\n",
    "import glob\n",
    "\n",
    "droplet_paths = glob.glob(\"data/mouse/*droplet*\")\n",
    "facs_paths = glob.glob(\"data/mouse/*facs*\")\n",
    "print(droplet_paths)\n",
    "\n",
    "droplet_tissues = set()\n",
    "facs_tissues = set()\n",
    "for file_path in droplet_paths:\n",
    "    droplet_tissues.add(file_path.split(\"droplet_\")[-1].split(\".\")[0])\n",
    "for file_path in facs_paths:\n",
    "    facs_tissues.add(file_path.split(\"facs_\")[-1].split(\".\")[0])\n",
    "\n",
    "both_tissues = droplet_tissues.intersection(facs_tissues)\n",
    "print(len(droplet_tissues), len(facs_tissues), len(both_tissues))\n",
    "\n",
    "\n",
    "droplet_only_tissues = droplet_tissues - facs_tissues\n",
    "facs_only_tissues = facs_tissues - droplet_tissues\n",
    "\n",
    "both_tissues = list(both_tissues)\n",
    "all_tissues = droplet_tissues.union(facs_tissues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tissue | Droplet | FACS\")\n",
    "for tissue in both_tissues:\n",
    "    droplet_h5raw = sc.read_h5ad(f'data/mouse/droplet_{tissue}.h5ad')\n",
    "    facs_h5raw = sc.read_h5ad(f'data/mouse/facs_{tissue}.h5ad')\n",
    "    print(f\"{tissue} | {droplet_h5raw.X.shape} | {facs_h5raw.X.shape}\")\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all tissues into one file\n",
    "combine_tissues_and_methods_both(list(all_tissues), 'ALL_METHODS', threshold=0.0, all_methods=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate data file for each tissue\n",
    "\n",
    "tissues = all_tissues\n",
    "threshold = 0.0\n",
    "combine_methods_for_tissues(tissues, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datafile for all tissues that have both methods\n",
    "\n",
    "output_name = 'BOTH'\n",
    "threshold = 0.2\n",
    "combine_tissues_and_methods_both(both_tissues, output_name, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datafile for all tissues that have only FACS method\n",
    "\n",
    "output_name = 'ALL_FACS'\n",
    "threshold = 0.0\n",
    "combine_FACS_tissues(facs_only_tissues, output_name, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabula Sapiens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and join data for Epithelial, Endothelial and Stromal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_names = [\"TS_epithelial\",\n",
    "              \"TS_endothelial\",\n",
    "              \"TS_stromal\", \n",
    "              ]\n",
    "\n",
    "for name in type_names:\n",
    "    process_h5ad(folder='data/sapiens', tissue=name, threshold=0.0, only_filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "full_set = set()\n",
    "for name in [\"TS_epithelial\", \"TS_endothelial\"]:\n",
    "    _, _, gene_list = load_h5ad_data('sapiens', name, filtered=True)\n",
    "    if len(full_set) == 0:\n",
    "        full_set = set(gene_list)\n",
    "    full_set = full_set.intersection(set(gene_list))\n",
    "\n",
    "X, y1, gene_list = load_h5ad_data('sapiens', \"TS_epithelial\", filtered=True)\n",
    "X1 = pd.DataFrame(X).loc[:,pd.Index(gene_list).isin(full_set)].to_numpy()\n",
    "#y1 = y.loc[:,pd.Index(gene_list).isin(full_set)]\n",
    "\n",
    "X, y2, gene_list = load_h5ad_data('sapiens', \"TS_endothelial\", filtered=True)\n",
    "X2 = pd.DataFrame(X).loc[:,pd.Index(gene_list).isin(full_set)].to_numpy()\n",
    "#y2 = y.loc[:,pd.Index(gene_list).isin(full_set)]\n",
    "\n",
    "X, y3, gene_list = load_h5ad_data('sapiens', \"TS_stromal\", filtered=True)\n",
    "X3 = pd.DataFrame(X).loc[:,pd.Index(gene_list).isin(full_set)].to_numpy()\n",
    "#y3 = y.loc[:,pd.Index(gene_list).isin(full_set)]\n",
    "\n",
    "X = np.concatenate([X1, X2, X3])\n",
    "y = pd.concat([y1, y2, y3])\n",
    "\n",
    "Xn, yn, gene_listn = load_h5ad_data('sapiens', \"TS_endothelial\", filtered=True)\n",
    "np.save(f'data/sapiens/ees_filtered_genes.npy', list(pd.DataFrame(Xn).loc[:,pd.Index(gene_listn).isin(full_set)].columns))\n",
    "np.save(f'data/sapiens/ees_filtered.npy', X)\n",
    "y.to_csv(f'data/sapiens/ees_meta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get only high variance genes from the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (218317, 51078)\n"
     ]
    }
   ],
   "source": [
    "X, y, gene_list = load_data('sapiens',\n",
    "                            'TS_EES',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_thresholding(X, threshold=0.01, chunk_size=1000):\n",
    "    num_samples, num_features = X.shape\n",
    "    retained_indices = []\n",
    "\n",
    "    for start in range(0, num_features, chunk_size):\n",
    "        end = min(start + chunk_size, num_features)\n",
    "        chunk = X[:, start:end]\n",
    "        variances = np.var(chunk, axis=0)\n",
    "        retained_indices.extend(np.where(variances > threshold)[0] + start)\n",
    "    \n",
    "    return retained_indices\n",
    "\n",
    "# Apply variance thresholding\n",
    "threshold = 0.05  # Example threshold value\n",
    "retained_indices = variance_thresholding(X, threshold=threshold)\n",
    "\n",
    "# Filter the data\n",
    "X_high_variance = X[:, retained_indices]\n",
    "gene_list_high_variance = gene_list[retained_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218317, 6926)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_high_variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered data\n",
    "H5_FOLDER = 'data/sapiens'  # Replace with your directory\n",
    "np.save(f'{H5_FOLDER}/TS_EES_hv_filtered.npy', X_high_variance)\n",
    "np.save(f'{H5_FOLDER}/TS_EES_hv_filtered_genes.npy', gene_list_high_variance)\n",
    "y.to_csv(f'{H5_FOLDER}/TS_EES_hv_meta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose three donors from different age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Test Donors: ['TSP5', 'TSP3', 'TSP2']\n"
     ]
    }
   ],
   "source": [
    "# Donor ages provided\n",
    "ages = {\n",
    "    'TSP6': 67, 'TSP7': 69, 'TSP4': 38, 'TSP5': 40,\n",
    "    'TSP3': 57, 'TSP10': 33, 'TSP12': 74, 'TSP9': 37,\n",
    "    'TSP8': 56, 'TSP14': 59, 'TSP15': 46, 'TSP1': 59, 'TSP2': 61\n",
    "}\n",
    "\n",
    "# Convert the ages to a DataFrame\n",
    "ages_df = pd.DataFrame(list(ages.items()), columns=['Donor', 'Age'])\n",
    "\n",
    "# Sort the donors by age\n",
    "ages_df = ages_df.sort_values(by='Age')\n",
    "\n",
    "# Divide the donors into three groups: younger, middle, and older\n",
    "n = len(ages_df)\n",
    "younger_group = ages_df.iloc[:n//3]\n",
    "middle_group = ages_df.iloc[n//3:2*n//3]\n",
    "older_group = ages_df.iloc[2*n//3:]\n",
    "\n",
    "# Select one donor from each group\n",
    "selected_test_donors = [\n",
    "    younger_group.sample(1).iloc[0]['Donor'],\n",
    "    middle_group.sample(1).iloc[0]['Donor'],\n",
    "    older_group.sample(1).iloc[0]['Donor']\n",
    "]\n",
    "\n",
    "print(\"Selected Test Donors:\", selected_test_donors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External datasets (.mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/mouse/E-MTAB-8077-quantification-raw-files/E-MTAB-8077.aggregated_filtered_counts.mtx'\n",
    "\n",
    "# Read the .mtx file using scipy.io.mmread()\n",
    "sparse_matrix = mmread(data_path)\n",
    "\n",
    "# Convert the sparse matrix to a dense NumPy array\n",
    "expression_data = sparse_matrix.toarray().T\n",
    "\n",
    "\n",
    "with open(data_path+'_rows', 'r') as file:\n",
    "    gene_names = file.read().splitlines()\n",
    "gene_names = [gene.split('\\t')[0] for gene in gene_names]\n",
    "\n",
    "\n",
    "# Read the cell names\n",
    "with open(data_path+'_cols', 'r') as file:\n",
    "    cell_names = file.read().splitlines()\n",
    "\n",
    "metadata_path = 'data/mouse/E-MTAB-8077-quantification-raw-files/ExpDesign-E-MTAB-8077.tsv'\n",
    "\n",
    "with open(metadata_path) as file:\n",
    "    metadata = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "# Function to extract text within square brackets\n",
    "def extract_bracket_text(text):\n",
    "    match = re.search(r'\\[(.*?)\\]', text)\n",
    "    return match.group(1) if match else text\n",
    "\n",
    "# Rename columns to only have the parts within square brackets\n",
    "metadata.columns = [extract_bracket_text(col) for col in metadata.columns]\n",
    "\n",
    "# Handle duplicates by appending a suffix to duplicate names\n",
    "def handle_duplicates(cols):\n",
    "    counts = {}\n",
    "    new_cols = []\n",
    "    for col in cols:\n",
    "        if col in counts:\n",
    "            counts[col] += 1\n",
    "            new_cols.append(f\"{col}.{counts[col]}\")\n",
    "        else:\n",
    "            counts[col] = 0\n",
    "            new_cols.append(col)\n",
    "    return new_cols\n",
    "\n",
    "new_columns = [extract_bracket_text(col) for col in metadata.columns]\n",
    "\n",
    "# Apply the function to handle duplicates\n",
    "metadata.columns = handle_duplicates(new_columns)\n",
    "\n",
    "# Remove duplicated rows based on the 'ENA_SAMPLE' column\n",
    "#metadata = metadata.drop_duplicates(subset='ENA_SAMPLE')\n",
    "\n",
    "# Print the shape of the resulting NumPy array\n",
    "print(\"Expression data shape:\", expression_data.shape)\n",
    "\n",
    "# Print the number of genes and cells\n",
    "print(\"Number of genes:\", len(gene_names))\n",
    "print(\"Number of cells:\", len(cell_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "# Query gene symbols using Ensembl gene IDs\n",
    "gene_info = mg.querymany(gene_names, scopes='ensembl.gene', fields='symbol', species='mouse')\n",
    "\n",
    "# Create a dictionary to store the mapping of Ensembl gene IDs to gene symbols\n",
    "gene_id_to_symbol = {}\n",
    "\n",
    "# Iterate over the query results and populate the dictionary\n",
    "for gene in gene_info:\n",
    "    ensembl_id = gene.get('query')\n",
    "    symbol = gene.get('symbol')\n",
    "    \n",
    "    if ensembl_id and symbol:\n",
    "        gene_id_to_symbol[ensembl_id] = symbol\n",
    "\n",
    "# Create a list to store the gene symbols without duplicates\n",
    "gene_symbols = []\n",
    "\n",
    "# Iterate over the original gene names and retrieve the corresponding gene symbols\n",
    "for gene_id in gene_names:\n",
    "    symbol = gene_id_to_symbol.get(gene_id, 'N/A')\n",
    "    gene_symbols.append(symbol)\n",
    "\n",
    "# Print the number of genes and the number of genes with no hit\n",
    "print(f\"Total genes: {len(gene_names)}\")\n",
    "print(f\"Genes with no hit: {gene_symbols.count('N/A')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/mouse'\n",
    "tissue = '8077'\n",
    "\n",
    "metadata.to_csv(f'{folder}/{tissue}_meta.csv')\n",
    "np.save(f'{folder}/{tissue}_filtered_genes.npy', gene_symbols)\n",
    "np.save(f'{folder}/{tissue}_filtered.npy', expression_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25b634e077fef15ed1bff16db0d2a3c0e150951a18d76805427f4bb8c8ca9220"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
